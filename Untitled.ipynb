{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d514217a-8cb9-4824-9da6-942d785be80d",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "89cdbaa0-36b2-43fa-bac7-c8bf4d2698ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "890019b8-457e-4252-bee5-eef347aa121a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CUADv1.json', 'test.json', 'train_separate_questions.json']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all the files\n",
    "os.listdir('../cuad-demo/cuad-data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "43f0d641-c109-491e-b368-8ecf55ef45f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../cuad-demo/cuad-data/train_separate_questions.json', 'r') as read_file:\n",
    "    train = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "18aabb44-0c11-4610-8b07-4619fcc075ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = []\n",
    "\n",
    "for i in range(len(train['data'])):\n",
    "    train_new.append(train['data'][i]['paragraphs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b096edac-d64f-4847-992a-b0f70e229b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../cuad-demo/cuad-data/test.json', 'r') as read_file:\n",
    "    test = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9225e5d0-2376-4429-8d5f-da6f56a68d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new = []\n",
    "\n",
    "for i in range(len(test['data'])):\n",
    "    test_new.append(test['data'][i]['paragraphs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "230514fa-6b44-4718-89fc-fa5817f547ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from simpletransformers.question_answering import QuestionAnsweringModel, QuestionAnsweringArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "db8be5c2-5e38-4d23-9126-da33c7d6d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model type\n",
    "model_type = 'roberta'\n",
    "if model_type == 'roberta':\n",
    "    model_name = 'roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "97c9147c-2897-46d4-b19c-62bb37195516",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = QuestionAnsweringArgs()\n",
    "model_args.train_batch_size = 16\n",
    "model_args.evaluate_during_training=True\n",
    "model_args.n_best_size = 1\n",
    "model_args.num_train_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b9c369ca-fc19-4bf7-b551-36fdf133a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Advanced Methodology\n",
    "train_args = {\n",
    "    \"reprocess_input_data\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"use_cached_eval_features\": True,\n",
    "    \"output_dir\": f\"outputs/{model_type}\",\n",
    "    \"best_model_dir\": f\"outputs/{model_type}/best_model\",\n",
    "    \"evaluate_during_training\": True,\n",
    "    \"max_seq_length\": 128,\n",
    "    \"num_train_epochs\": 5,\n",
    "    \"evaluate_during_training_steps\": 1000,\n",
    "    \"wandb_project\": \"Question Answer Application\",\n",
    "    \"wandb_kwargs\": {\"name\": model_name},\n",
    "    \"save_model_every_epoch\": False,\n",
    "    \"save_eval_checkpoints\": False,\n",
    "    \"n_best_size\":3,\n",
    "    # \"use_early_stopping\": True,\n",
    "    # \"early_stopping_metric\": \"mcc\",\n",
    "    # \"n_gpu\": 2,\n",
    "    # \"manual_seed\": 4,\n",
    "    # \"use_multiprocessing\": False,\n",
    "    \"train_batch_size\": 128,\n",
    "    \"eval_batch_size\": 64\n",
    "    # \"config\": {\n",
    "    #     \"output_hidden_states\": True\n",
    "    # }\n",
    "    # 'hub_token': access_token\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "17b1d0fb-a6b7-43a7-a758-7b7e41501acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "access_token = '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'\n",
    "model = QuestionAnsweringModel(\n",
    "    model_type,model_name, args=train_args, use_cuda=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e3a7bc13-a808-4dab-915f-77a92e447609",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [120]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\test\\lib\\site-packages\\simpletransformers\\question_answering\\question_answering_model.py:448\u001b[0m, in \u001b[0;36mQuestionAnsweringModel.train_model\u001b[1;34m(self, train_data, output_dir, show_running_loss, args, eval_data, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m         train_examples \u001b[38;5;241m=\u001b[39m train_data\n\u001b[1;32m--> 448\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_and_cache_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    452\u001b[0m global_step, training_details \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m    453\u001b[0m     train_dataset,\n\u001b[0;32m    454\u001b[0m     output_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    458\u001b[0m )\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\test\\lib\\site-packages\\simpletransformers\\question_answering\\question_answering_model.py:288\u001b[0m, in \u001b[0;36mQuestionAnsweringModel.load_and_cache_examples\u001b[1;34m(self, examples, evaluate, no_cache, output_examples)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_cache:\n\u001b[0;32m    286\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mcache_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 288\u001b[0m examples \u001b[38;5;241m=\u001b[39m \u001b[43mget_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m evaluate \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m cached_features_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    292\u001b[0m     args\u001b[38;5;241m.\u001b[39mcache_dir,\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcached_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    294\u001b[0m         mode, args\u001b[38;5;241m.\u001b[39mmodel_type, args\u001b[38;5;241m.\u001b[39mmax_seq_length, \u001b[38;5;28mlen\u001b[39m(examples)\n\u001b[0;32m    295\u001b[0m     ),\n\u001b[0;32m    296\u001b[0m )\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\test\\lib\\site-packages\\simpletransformers\\question_answering\\question_answering_utils.py:162\u001b[0m, in \u001b[0;36mget_examples\u001b[1;34m(examples_to_process, is_training, version_2_with_negative)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    160\u001b[0m                 answers \u001b[38;5;241m=\u001b[39m qa[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswers\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 162\u001b[0m         example \u001b[38;5;241m=\u001b[39m \u001b[43mSquadExample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[43mqas_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqas_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquestion_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43manswer_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manswer_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_position_character\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_position_character\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_impossible\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_impossible\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43manswers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manswers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m         examples\u001b[38;5;241m.\u001b[39mappend(example)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m examples\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\test\\lib\\site-packages\\transformers\\data\\processors\\squad.py:749\u001b[0m, in \u001b[0;36mSquadExample.__init__\u001b[1;34m(self, qas_id, question_text, context_text, answer_text, start_position_character, title, answers, is_impossible)\u001b[0m\n\u001b[0;32m    747\u001b[0m             doc_tokens[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m c\n\u001b[0;32m    748\u001b[0m         prev_is_whitespace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 749\u001b[0m     \u001b[43mchar_to_word_offset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdoc_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc_tokens \u001b[38;5;241m=\u001b[39m doc_tokens\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchar_to_word_offset \u001b[38;5;241m=\u001b[39m char_to_word_offset\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train_model(train_new, eval_data=test_new, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c89d9-7c7d-4c46-a792-1974a9be6754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
